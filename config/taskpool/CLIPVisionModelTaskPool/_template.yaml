_target_: fusion_bench.taskpool.CLIPVisionModelTaskPool
_version_: "0.2"
test_datasets: ??? # The datasets to evaluate the model on
base_model: openai/clip-vit-base-patch32
clip_model:
  _target_: transformers.CLIPModel
  pretrained_model_name_or_path: ${..base_model}
processor:
  _target_: transformers.CLIPProcessor
  pretrained_model_name_or_path: ${..base_model}
loader_kwargs:
  batch_size: 128
  num_workers: 8
  pin_memory: True
  drop_last: False
  shuffle: False

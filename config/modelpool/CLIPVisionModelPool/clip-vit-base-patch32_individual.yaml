defaults:
  - CLIPVisionModelPool@: _template
  - /model/clip-vit@models:
      - clip-vit-base-patch32
processor:
  _target_: transformers.CLIPProcessor
  pretrained_model_name_or_path: openai/clip-vit-base-patch32
